{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be861797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = fetch_20newsgroups(subset='all', categories=None, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "X_labeled, X_unlabeled, y_labeled, _ = train_test_split(data.data, data.target, test_size=0.8, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_labeled = vectorizer.fit_transform(X_labeled)\n",
    "X_unlabeled = vectorizer.transform(X_unlabeled)\n",
    "\n",
    "# Train the initial model on labeled data\n",
    "clf = SVC(kernel='linear', random_state=42)\n",
    "clf.fit(X_labeled, y_labeled)\n",
    "\n",
    "# Pseudo-labeling: Predict labels for unlabeled data and add confident predictions to labeled data\n",
    "pseudo_labels = clf.predict(X_unlabeled)\n",
    "high_confidence_mask = clf.decision_function(X_unlabeled).max(axis=1) > 0.5  # Adjust confidence threshold if needed\n",
    "X_pseudo_labeled = X_unlabeled[high_confidence_mask]\n",
    "y_pseudo_labels = pseudo_labels[high_confidence_mask]\n",
    "\n",
    "# Retrain the model with pseudo-labeled data added to labeled data\n",
    "X_combined = np.vstack([X_labeled.toarray(), X_pseudo_labeled.toarray()])\n",
    "y_combined = np.concatenate([y_labeled, y_pseudo_labels])\n",
    "clf.fit(X_combined, y_combined)\n",
    "\n",
    "# Evaluate the model on the test set (you can split X_unlabeled for testing if desired)\n",
    "X_test = X_unlabeled\n",
    "y_test = clf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(data.target[-len(y_test):], y_test)\n",
    "precision = precision_score(data.target[-len(y_test):], y_test, average='weighted')\n",
    "recall = recall_score(data.target[-len(y_test):], y_test, average='weighted')\n",
    "f1 = f1_score(data.target[-len(y_test):], y_test, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7bd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the movie review dataset (you can replace this with your dataset)\n",
    "# Assuming the dataset has 'text' and 'label' columns where label is 0 (negative) or 1 (positive)\n",
    "data = pd.read_csv('movie_reviews.csv')\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "y = data['label']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Discuss the assumption of feature independence in Naive Bayes\n",
    "print(\"\\nAssumption of Feature Independence:\")\n",
    "print(\"Naive Bayes assumes that features (words) are conditionally independent given the class label.\")\n",
    "print(\"This means that the occurrence of a particular word in a document is independent of the occurrence of other words,\")\n",
    "print(\"given whether the document is positive or negative. Despite this simplifying assumption, Naive Bayes often performs\")\n",
    "print(\"well in practice for text classification tasks, especially when paired with techniques like TF-IDF or word embeddings.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
